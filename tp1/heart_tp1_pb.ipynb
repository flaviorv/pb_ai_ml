{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjSicsiWdxjl",
        "outputId": "390f6552-e798-4ae5-a2c1-ac82a3a2f89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k: 10 accuracy: 0.90\n",
            "k: 60 accuracy: 0.88\n",
            "k: 110 accuracy: 0.88\n",
            "k: 160 accuracy: 0.88\n",
            "k: 210 accuracy: 0.87\n",
            "k: 260 accuracy: 0.86\n",
            "k: 310 accuracy: 0.85\n",
            "k: 360 accuracy: 0.86\n",
            "k: 410 accuracy: 0.85\n",
            "k: 460 accuracy: 0.84\n",
            "k: 510 accuracy: 0.84\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Obtendo dataset do repositório\n",
        "url = 'https://raw.githubusercontent.com/professortiagoinfnet/inteligencia_artificial/refs/heads/main/heart.csv'\n",
        "heart_df = pd.read_csv(url).dropna()\n",
        "\n",
        "#Separando as features e o target\n",
        "columns = list(heart_df.head())\n",
        "target = columns.pop()\n",
        "features = columns\n",
        "\n",
        "#Separando os dados de treino dos de validação\n",
        "x_train, x_val, y_train, y_val = train_test_split(heart_df[features], heart_df[target], train_size=0.80)\n",
        "\n",
        "#Transformando variáveis categóricas com BinaryEncoding e OneHotEncoding,\n",
        "#enquanto as contínuas tem suas escalas modificadas com StandardScaler.\n",
        "f_continuous = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
        "f_binary = ['Sex', 'ExerciseAngina']\n",
        "f_multiclass = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "        ('continuous', RobustScaler(), f_continuous),\n",
        "        ('binary', OrdinalEncoder(), f_binary),\n",
        "        ('multiclass', OneHotEncoder(handle_unknown='ignore'), f_multiclass)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "x_train_transformed = preprocessor.fit_transform(x_train)\n",
        "x_val_transformed = preprocessor.transform(x_val)\n",
        "\n",
        "#Aplicando KNN como modelo de previsão e verificando\n",
        "#a acurácia com diferentes k vizinhos\n",
        "for k in range(10, 511, 50):\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(x_train_transformed, y_train)\n",
        "  predicted = knn.predict(x_val_transformed)\n",
        "  print(f'k: {k} accuracy: {accuracy_score(y_val, predicted):.2f}')\n"
      ]
    }
  ]
}