{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi5p+7dbpd+IeW7BSyMSj1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flaviorv/pb_ai_ml/blob/main/pb_tp5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8i8itv6X0OL"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import shap\n",
        "except:\n",
        "  !pip install shap\n",
        "  import shap\n",
        "\n",
        "import spacy\n",
        "import shap\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shap.plots\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "from shap import TreeExplainer\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Carregando o modelo de lematização do scipy\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "\n",
        "# Função para retirar as tags HTML dos documentos\n",
        "def strip_html(text):\n",
        "  return BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "# Função para aplicar a lemmatização\n",
        "def lemmatize_text(text):\n",
        "  doc = nlp(text)\n",
        "  return \" \".join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])\n",
        "\n",
        "# Função para retornar as palavras de cada tópico gerado pelo LDA\n",
        "def get_topic_words(lda_model, feature_names, n_top_words=10):\n",
        "  topic_words = []\n",
        "  for topic in lda_model.components_:\n",
        "    top_indices = topic.argsort()[-n_top_words:][::-1]\n",
        "    top_words = [feature_names[i] for i in top_indices]\n",
        "    topic_words.append(top_words)\n",
        "  return topic_words\n",
        "\n",
        "# Função para pegar o tópico que melhor representa cada documento e retornar uma\n",
        "# contagem que mostra em quantos documentos cada tópico está presente\n",
        "def count_documents(lda_matrix):\n",
        "  dominant_topic = lda_matrix.argmax(axis=1)\n",
        "  topic_counts = Counter(dominant_topic)\n",
        "  return topic_counts\n",
        "\n",
        "# Função para imprimir as palavras mais importantes e a contagem de documentos de cada tópico\n",
        "def print_lda_topics(lda_model, lda_matrix, feature_names, n_top_words=10):\n",
        "  topics = get_topic_words(lda_model, feature_names, n_top_words)\n",
        "  counts = count_documents(lda_matrix)\n",
        "  for topic_idx, (topic, count) in enumerate(zip(topics, list(counts.values()))):\n",
        "    print(f\"Topic {topic_idx}:\", end=' ')\n",
        "    for word_idx, word in enumerate(topic):\n",
        "      print(f\"{word}\", end=' ')\n",
        "    print(f'- docs: {count}')\n",
        "\n",
        "# Função para rodar vários n_topics e achar o melhor número de tópicos visualmente\n",
        "# Retorna um dicionário de n_topic: lda_model\n",
        "def find_best_n_topics(x_vec, feature_names, n_topics_list, n_top_words=10):\n",
        "  lda_models = {}\n",
        "  for n_topics in n_topics_list:\n",
        "    lda_tmp = LatentDirichletAllocation(\n",
        "      n_components=n_topics,\n",
        "      doc_topic_prior=0.1,\n",
        "      topic_word_prior=0.01,\n",
        "      random_state=42,\n",
        "      n_jobs=-1\n",
        "    )\n",
        "    lda_matrix = lda_tmp.fit_transform(x_vec)\n",
        "    print(f'\\nTopics: {n_topics}')\n",
        "    print_lda_topics(lda_tmp, lda_matrix, feature_names)\n",
        "    lda_models[n_topics] = lda_tmp\n",
        "  return lda_models\n",
        "\n",
        "# Carregando o dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/flaviorv/pb_ai_ml/refs/heads/main/datasets/IMDB%20Dataset.csv')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separando features e target\n",
        "x = df['review']\n",
        "y = df['sentiment']\n",
        "\n",
        "# Dividindo entre treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, stratify=y, test_size=0.30)\n",
        "\n",
        "# Retirando as tags HTML e aplicando a lematização para o calcular o melhor hiperparâmetro do número de tópicos\n",
        "x_train_lemmatized = x_train.apply(strip_html).apply(lemmatize_text)\n",
        "x_test_lemmatized = x_test.apply(strip_html).apply(lemmatize_text)\n",
        "\n",
        "# Questão 1 - Criação das features: Computar o Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "# para representar a importância das palavras em um conjunto de documentos.\n",
        "\n",
        "# Stop words customizadas de acordo com o contexto (palavras como film e movie são muito genéricas para o nosso contexto, não trazem informação relevante)\n",
        "custom_stop_words = ['film', 'movie', 'good', 'bad', 'just', 'like', 'great', 'really', 'story', 'time', 'watch', 'make', 'think', 'character'] + list(ENGLISH_STOP_WORDS)\n",
        "# Aplicando o TF-IDF para criar tokens com seus respectivos pesos por documentos\n",
        "vectorizer = TfidfVectorizer(stop_words=custom_stop_words, max_df=0.65, min_df=20)\n",
        "x_vec = vectorizer.fit_transform(x_train_lemmatized)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Questão 2 - Modelagem de Tópicos com LDA: Aplicar o algoritmo LDA para identificar tópicos prevalentes nos dados.\n",
        "# A seleção do número de tópicos será baseada em métricas de coerência para garantir a relevância e a distinção entre\n",
        "# os tópicos identificados.\n",
        "\n",
        "# O LDA irá aleatoriamente atribuir tópicos para cada token do TFIDF, após isso ele irá comparar cada token com os tokens do próprio\n",
        "# documento e com todos os tokens, podendo reatribuir um novo tópico para o token em questão se ver que ele se encaixa melhor em outro contexto.\n",
        "# Ele faz as comparações iterativamente até que não haja mais correções a fazer e os tópicos estejam coerentes. Ele retorna uma matriz de\n",
        "# documentos por tópicos, onde os valores são as probabilidades do documento pertencer aos tópicos. Isso ajuda a reduzir a dimensionalidade e\n",
        "# pode trazer significado para usarmos em um aprendizado supervisionado\n",
        "\n",
        "# Com 10 n_topic, os tópicos parecem ter alguma coesão. Nele, o tópico 0 parece ter haver com sentimento negativo, o tópico 1 é sobre espaço, alienígenas.\n",
        "# O 4 parece estar mais relacionado à comédia, mas tem o batman no meio também. O 7 parece ter haver com clássicos, o 9 é sobre música.\n",
        "\n",
        "# Tópicos que são dominantes em poucos documentos, não necessariamente são inúteis. Eles podem significar algo, pois podem ter pesos em diversos\n",
        "# documentos em que não são dominantes,  contribuindo para o algoritmo encontrar padrões.\n",
        "\n",
        "# Além da avaliação visual, serão testados todos os números de n_topics no grid para ver qual se sairá melhor\n",
        "\n",
        "n_topics = [2, 3, 5, 10, 15]\n",
        "lda_models = find_best_n_topics(x_vec, feature_names, n_topics)\n",
        "\n",
        "# Questão 3 - Classificação de Textos: Desenvolver modelos de classificação para categorizar os textos com base\n",
        "# nos tópicos identificados. Você pode escolher qualquer modelo aprendido ao longo do curso e deve escolher o\n",
        "# melhor modelo usando as técnicas aprendidas, como busca de hiperparâmetros e validação cruzada\n",
        "\n",
        "# Como o modelo leva um grande tempo de processamento, foi usado o Randomized Search para que limitemos o número de iterações.\n",
        "# Foi escolhido o Random Forest por ser um modelo caixa preta, como o objetivo é a análise desse tipo de modelo\n",
        "\n",
        "# Hiperparâmetros\n",
        "grid_params = {\n",
        "  'lda__n_components': n_topics,\n",
        "  'classifier__n_estimators': [100, 300],\n",
        "  'classifier__max_depth': [10, 15, 20],\n",
        "  'classifier__min_samples_split': [2, 5, 10],\n",
        "  'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Sequência de etapas\n",
        "pipeline = Pipeline([\n",
        "  ('tfidf', TfidfVectorizer(stop_words=custom_stop_words, max_df=0.65, min_df=20)),\n",
        "  ('lda', LatentDirichletAllocation(n_components=n_topics, random_state=42)),\n",
        "  ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Treinamento com Grid Search e validação cruzada para a escolha do melhor modelo\n",
        "grid = RandomizedSearchCV(pipeline, grid_params, cv=3, n_iter=5, scoring='f1_macro', n_jobs=-1)\n",
        "grid.fit(x_train_lemmatized, y_train)\n",
        "y_pred = grid.predict(x_test_lemmatized)\n",
        "\n",
        "# Questão 4 - Avaliação de Desempenho: O desempenho dos modelos de classificação será avaliado utilizando métricas como precisão, recall, F1-score e AUC-ROC.\n",
        "\n",
        "# O modelo conseguiu ter um desempenho médio. Possui 72% de acurácia. Seu recall foi o ponto fraco, 33% dos reviews positivos são classificados como reviews\n",
        "# negatios.\n",
        "\n",
        "# A curva ROC, mostra a taxa de Falsos Positivos x Verdadeiros Positivos\n",
        "# Se mudaros o threshold para ter uma recall maior, a precisão cai. Dependendo do que o cliente deseja, o threshold pode ser alterado\n",
        "\n",
        "# Recall, precisão, f1-score, acurácia\n",
        "print('\\nBest params:', grid.best_params_)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Prababilidades da classe 'positive' para gerar a curva ROC\n",
        "y_proba = grid.predict_proba(x_test_lemmatized)[:, 1]\n",
        "\n",
        "# Alguns métodos como o roc_curve não aceitam strings\n",
        "sentiment_to_numeric = {'positive': 1, 'negative': 0}\n",
        "y_test_numeric = y_test.map(sentiment_to_numeric)\n",
        "y_pred_numeric = np.array([sentiment_to_numeric[s] for s in y_pred])\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test_numeric, y_proba)\n",
        "auc = roc_auc_score(y_test_numeric, y_proba)\n",
        "\n",
        "# Plotando a curva ROC\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel(\"False Positives (FPR)\")\n",
        "plt.ylabel(\"True Positives (TPR)\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Questão 5 - Visualização com t-SNE: Aplicar a técnica de t-SNE nos dados textuais vetorizados para reduzir a dimensionalidade e visualizar\n",
        "# os agrupamentos de documentos de maneira intuitiva, facilitando a identificação de padrões e outliers.\n",
        "\n",
        "# O T-SNE é útil para visualização gráfica, diminuindo a dimensionalidade. Ele faz isso preservando as distâncias locais.\n",
        "# O T-SNE calcula a probabilidade de um ponto ser vizinho de outro, quanto mais próximo, maior essa probabilidade e ele tende\n",
        "# a preservar essa distância local, mantendo-os próximos no novo espaço que ele cria de baixa dimensionalidade.\n",
        "\n",
        "# Instanciando o T-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=10, max_iter=1000, init='random')\n",
        "\n",
        "# Utilizando o TF-IDF do grid, que deu fit nos dados dos folds de treino\n",
        "vectorizer = grid.best_estimator_.named_steps['tfidf']\n",
        "x_test_vec = vectorizer.transform(x_test_lemmatized)\n",
        "# Reduzindo a dimensionalidade\n",
        "x_test_2d = tsne.fit_transform(x_test_vec)\n",
        "\n",
        "# Plotando o gráfico com o target real\n",
        "plt.figure(figsize=(8,6))\n",
        "scatter = plt.scatter(x_test_2d[:,0], x_test_2d[:,1], c=y_test_numeric, cmap='tab10', alpha=0.6)\n",
        "plt.title(\"t-SNE Visualization (True Sentiments)\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.legend(*scatter.legend_elements(), title=\"Topics\")\n",
        "plt.show()\n",
        "\n",
        "# Plotando o gráfico com as previsões do modelo\n",
        "plt.figure(figsize=(8,6))\n",
        "scatter = plt.scatter(x_test_2d[:,0], x_test_2d[:,1], c=y_pred_numeric, cmap='tab10', alpha=0.6)\n",
        "plt.title(\"t-SNE Visualization (Predicted Sentiments)\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.legend(*scatter.legend_elements(), title=\"Topics\")\n",
        "plt.show()\n",
        "\n",
        "# Os plots do T-SNE não mostraram uma boa separação entre as classes. Pode indicar dificuldade na classificação\n",
        "\n",
        "# Questão 6 - Interpretação de Modelos com LIME, SHAP e Force-Plot: Utilizar SHAP para explicar as previsões individuais, identificando a contribuição de cada feature\n",
        "# para a decisão do modelo. O force-plot será usado para visualizar essas contribuições de maneira agregada, oferecendo insights sobre a lógica de decisão do modelo.\n",
        "\n",
        "# O SHAP calcula quanto cada feature contribuiu para a previsão de determinada amostra. Ele é otimizado para testar combinações sem e com cada feature, mas não faz isso\n",
        "# com força bruta, pois poderia ser inviável testar todas as combinações em muitos casos. Por isso, ele utiliza método de amostragem.\n",
        "\n",
        "# É necessário passar o modelo para que o SHAP entenda-o\n",
        "explainer = shap.TreeExplainer(grid.best_estimator_['classifier'])\n",
        "lda_model = grid.best_estimator_.named_steps['lda']\n",
        "\n",
        "# Preprocessamento\n",
        "x_test_vec = vectorizer.transform(x_test_lemmatized)\n",
        "x_test_lda = lda_model.transform(x_test_vec)\n",
        "\n",
        "# Escolhendo a primeira amostra do conjunto de teste para explicar\n",
        "sample = x_test_lda[0:1]\n",
        "\n",
        "# Calculando os valores de Shapley\n",
        "shap_values = explainer.shap_values(sample)\n",
        "\n",
        "# Inicializando o javascript para o plot\n",
        "shap.initjs()\n",
        "\n",
        "# Gerando o Force Plot para a classe 'positive'\n",
        "shap.force_plot(\n",
        "    explainer.expected_value[1],\n",
        "    shap_values[0, :, 1],\n",
        "    sample,\n",
        "    feature_names=[f'Topic {i}' for i in range(lda_model.n_components)]\n",
        ")\n",
        "\n",
        "# 7 - Análise dos resultados: Enumere as conclusões que podem ser tomadas a partir dos resultados obtidos.\n",
        "\n",
        "# O force plot nos mostra as features que mais contribuiram para a previsão. O valor previsto para a primeira amostra foi 0,\n",
        "# principalmente pelo Topico 0 que teve um valor shap de 0.83, bem maior que o das outras. Conhecidentemente,\n",
        "# o Tópico 0 é dominante em muito mais amostras que os demais, o que pode sugerir um enviesamento na criação dos tópicos.\n",
        "# Não apareceram features no plot que contribuiram significantemente para a classe 1 na primeira amostra"
      ]
    }
  ]
}